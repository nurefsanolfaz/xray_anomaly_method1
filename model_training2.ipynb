{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09db220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çalışma dizini: /Users/nurefsanolfaz/yap470_project/xray_anomaly_method1\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Proje köküne geç\n",
    "proj_root = \"/Users/nurefsanolfaz/yap470_project/xray_anomaly_method1\"\n",
    "os.chdir(proj_root)\n",
    "sys.path.insert(0, proj_root)\n",
    "\n",
    "print(\"Çalışma dizini:\", os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from src.method1.model_pipeline import build_pipeline\n",
    "from src.method1.evaluate import evaluate_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "os.makedirs(\"models/dataset2\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09604241",
   "metadata": {},
   "source": [
    "LBP + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02da50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = \"features/dataset2/lbp\"  # alternatif: 'hog', 'lbp', 'haralick'\n",
    "\n",
    "X_train = np.load(os.path.join(FEATURE_DIR, \"X_train.npy\"))\n",
    "y_train = np.load(os.path.join(FEATURE_DIR, \"y_train.npy\"))\n",
    "X_val = np.load(os.path.join(FEATURE_DIR, \"X_val.npy\"))\n",
    "y_val = np.load(os.path.join(FEATURE_DIR, \"y_val.npy\"))\n",
    "X_test = np.load(os.path.join(FEATURE_DIR, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(FEATURE_DIR, \"y_test.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9509e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model eğitiliyor...\n",
      "[INFO] Validation Accuracy: 0.2187\n",
      "\n",
      "[INFO] Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Atelectasis       0.21      0.30      0.25       450\n",
      "    Effusion       0.24      0.28      0.26       450\n",
      "Infiltration       0.17      0.15      0.16       450\n",
      "  No_Finding       0.24      0.20      0.22       450\n",
      "      Nodule       0.23      0.16      0.18       450\n",
      "\n",
      "    accuracy                           0.22      2250\n",
      "   macro avg       0.22      0.22      0.21      2250\n",
      "weighted avg       0.22      0.22      0.21      2250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/dataset2/pipeline_lbp_5nn.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "pipeline_5nn = build_pipeline(knn, use_pca=True, use_scaler=True)\n",
    "\n",
    "# Modeli eğit ve değerlendir\n",
    "evaluate_model(pipeline_5nn, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "joblib.dump(pipeline_5nn, \"models/dataset2/pipeline_lbp_5nn.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18095f4e",
   "metadata": {},
   "source": [
    "HOG + SVM(rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "691e3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = \"features/dataset2/hog\"  # alternatif: 'hog', 'lbp', 'haralick'\n",
    "\n",
    "X_train = np.load(os.path.join(FEATURE_DIR, \"X_train.npy\"))\n",
    "y_train = np.load(os.path.join(FEATURE_DIR, \"y_train.npy\"))\n",
    "X_val = np.load(os.path.join(FEATURE_DIR, \"X_val.npy\"))\n",
    "y_val = np.load(os.path.join(FEATURE_DIR, \"y_val.npy\"))\n",
    "X_test = np.load(os.path.join(FEATURE_DIR, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(FEATURE_DIR, \"y_test.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ff27227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model eğitiliyor...\n",
      "[INFO] Validation Accuracy: 0.3280\n",
      "\n",
      "[INFO] Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Atelectasis       0.33      0.34      0.34       450\n",
      "    Effusion       0.35      0.42      0.38       450\n",
      "Infiltration       0.26      0.16      0.20       450\n",
      "  No_Finding       0.41      0.44      0.43       450\n",
      "      Nodule       0.30      0.31      0.31       450\n",
      "\n",
      "    accuracy                           0.34      2250\n",
      "   macro avg       0.33      0.34      0.33      2250\n",
      "weighted avg       0.33      0.34      0.33      2250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/dataset2/pipeline_hog_svm.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1)\n",
    "pipeline_hog_svm = build_pipeline(svm, use_pca=True, use_scaler=True)\n",
    "\n",
    "# Modeli eğit ve değerlendir\n",
    "evaluate_model(pipeline_hog_svm, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "joblib.dump(pipeline_hog_svm, \"models/dataset2/pipeline_hog_svm.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39a6f2",
   "metadata": {},
   "source": [
    "LBP + KNN için farklı komşuluk sayılarıyla denedik. Çok büyük bir fark olmamakla birlikte n = 7 optimal olanı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd6f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = \"features/dataset2/lbp\"  # alternatif: 'hog', 'lbp', 'haralick'\n",
    "\n",
    "X_train = np.load(os.path.join(FEATURE_DIR, \"X_train.npy\"))\n",
    "y_train = np.load(os.path.join(FEATURE_DIR, \"y_train.npy\"))\n",
    "X_val = np.load(os.path.join(FEATURE_DIR, \"X_val.npy\"))\n",
    "y_val = np.load(os.path.join(FEATURE_DIR, \"y_val.npy\"))\n",
    "X_test = np.load(os.path.join(FEATURE_DIR, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(FEATURE_DIR, \"y_test.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ecf785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model eğitiliyor...\n",
      "[INFO] Validation Accuracy: 0.2013\n",
      "\n",
      "[INFO] Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Atelectasis       0.21      0.42      0.28       450\n",
      "    Effusion       0.22      0.27      0.24       450\n",
      "Infiltration       0.19      0.13      0.15       450\n",
      "  No_Finding       0.24      0.13      0.17       450\n",
      "      Nodule       0.24      0.13      0.16       450\n",
      "\n",
      "    accuracy                           0.21      2250\n",
      "   macro avg       0.22      0.21      0.20      2250\n",
      "weighted avg       0.22      0.21      0.20      2250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/dataset2/pipeline_lbp_3nn.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "pipeline_3nn = build_pipeline(knn, use_pca=True, use_scaler=True)\n",
    "\n",
    "# Modeli eğit ve değerlendir\n",
    "evaluate_model(pipeline_3nn, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "joblib.dump(pipeline_3nn, \"models/dataset2/pipeline_lbp_3nn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d39222fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model eğitiliyor...\n",
      "[INFO] Validation Accuracy: 0.2098\n",
      "\n",
      "[INFO] Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Atelectasis       0.22      0.34      0.26       450\n",
      "    Effusion       0.22      0.27      0.24       450\n",
      "Infiltration       0.17      0.15      0.16       450\n",
      "  No_Finding       0.26      0.20      0.22       450\n",
      "      Nodule       0.21      0.13      0.16       450\n",
      "\n",
      "    accuracy                           0.22      2250\n",
      "   macro avg       0.22      0.22      0.21      2250\n",
      "weighted avg       0.22      0.22      0.21      2250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/dataset2/pipeline_lbp_7nn.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipeline_7nn = build_pipeline(knn, use_pca=True, use_scaler=True)\n",
    "\n",
    "# Modeli eğit ve değerlendir\n",
    "evaluate_model(pipeline_7nn, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "joblib.dump(pipeline_7nn, \"models/dataset2/pipeline_lbp_7nn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f29c31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = \"features/dataset2/hog\"  # alternatif: 'hog', 'lbp', 'haralick'\n",
    "\n",
    "X_train = np.load(os.path.join(FEATURE_DIR, \"X_train.npy\"))\n",
    "y_train = np.load(os.path.join(FEATURE_DIR, \"y_train.npy\"))\n",
    "X_val = np.load(os.path.join(FEATURE_DIR, \"X_val.npy\"))\n",
    "y_val = np.load(os.path.join(FEATURE_DIR, \"y_val.npy\"))\n",
    "X_test = np.load(os.path.join(FEATURE_DIR, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(FEATURE_DIR, \"y_test.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85919021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model eğitiliyor...\n",
      "[INFO] Validation Accuracy: 0.2596\n",
      "\n",
      "[INFO] Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Atelectasis       0.26      0.30      0.28       450\n",
      "    Effusion       0.31      0.31      0.31       450\n",
      "Infiltration       0.23      0.21      0.22       450\n",
      "  No_Finding       0.29      0.32      0.30       450\n",
      "      Nodule       0.26      0.22      0.24       450\n",
      "\n",
      "    accuracy                           0.27      2250\n",
      "   macro avg       0.27      0.27      0.27      2250\n",
      "weighted avg       0.27      0.27      0.27      2250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/dataset2/pipeline_hog_7nn.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipeline_7nn = build_pipeline(knn, use_pca=True, use_scaler=True)\n",
    "\n",
    "# Modeli eğit ve değerlendir\n",
    "evaluate_model(pipeline_7nn, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "joblib.dump(pipeline_7nn, \"models/dataset2/pipeline_hog_7nn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f687d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model eğitiliyor...\n",
      "[INFO] Validation Accuracy: 0.2653\n",
      "\n",
      "[INFO] Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Atelectasis       0.25      0.27      0.26       450\n",
      "    Effusion       0.29      0.32      0.30       450\n",
      "Infiltration       0.22      0.20      0.21       450\n",
      "  No_Finding       0.36      0.34      0.35       450\n",
      "      Nodule       0.26      0.24      0.25       450\n",
      "\n",
      "    accuracy                           0.28      2250\n",
      "   macro avg       0.28      0.28      0.28      2250\n",
      "weighted avg       0.28      0.28      0.28      2250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/dataset2/pipeline_hog_mlp.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "pipeline_mlp = build_pipeline(mlp, use_pca=True, use_scaler=True)\n",
    "\n",
    "# Modeli eğit ve değerlendir\n",
    "evaluate_model(pipeline_mlp, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "joblib.dump(pipeline_mlp, \"models/dataset2/pipeline_hog_mlp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4faa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = \"features/dataset2/hog_lbp\"  # alternatif: 'hog', 'lbp', 'haralick'\n",
    "\n",
    "X_train = np.load(os.path.join(FEATURE_DIR, \"X_train.npy\"))\n",
    "y_train = np.load(os.path.join(FEATURE_DIR, \"y_train.npy\"))\n",
    "X_val = np.load(os.path.join(FEATURE_DIR, \"X_val.npy\"))\n",
    "y_val = np.load(os.path.join(FEATURE_DIR, \"y_val.npy\"))\n",
    "X_test = np.load(os.path.join(FEATURE_DIR, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(FEATURE_DIR, \"y_test.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8726f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Model eğitiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nurefsanolfaz/yap470_project/xray_anomaly_method1/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [16:23:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Validation Accuracy: 0.2653\n",
      "\n",
      "[INFO] Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.19      0.20       450\n",
      "           1       0.29      0.32      0.30       450\n",
      "           2       0.20      0.18      0.19       450\n",
      "           3       0.32      0.32      0.32       450\n",
      "           4       0.25      0.28      0.26       450\n",
      "\n",
      "    accuracy                           0.26      2250\n",
      "   macro avg       0.26      0.26      0.26      2250\n",
      "weighted avg       0.26      0.26      0.26      2250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/dataset2/pipeline_hog_lbp_xgb.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "pipeline_xgb = build_pipeline(xgb, use_pca=True, use_scaler=True)   \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Etiketleri encode et\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Modeli eğit ve değerlendir\n",
    "evaluate_model(pipeline_xgb, X_train, y_train, X_val, y_val, X_test, y_test)    \n",
    "joblib.dump(pipeline_xgb, \"models/dataset2/pipeline_hog_lbp_xgb.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0111417",
   "metadata": {},
   "source": [
    "Dataset1’de (Normal vs Pneumonia) HOG+LBP+Haralick öznitelikleri ve klasik ML modelleri (SVM, KNN, XGBoost, MLP) ile %80’in üzerinde doğruluk elde ederken, aynı kombinasyonlar Dataset2’nin beş sınıflı yapısında bariz biçimde başarısız oldu; bu da el yapımı öznitelik tabanlı yöntemlerin çok sınıflı doku farklılıklarını yakalamada yetersiz kaldığını gösteriyor. Bu nedenle CNN’siz kalmak istiyorsak Dataset2’yi “Normal vs Anomali” ikili sınıflandırmasına indirgemek veya doğrudan derin öğrenme tabanlı yaklaşımlara geçmek gerekecektir.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
